---
title: "assignment_2_Ramzi"
author: "Ramzi Chariag"
date: "2023-02-10"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load data, include=FALSE}
# CLEAR MEMORY
rm(list=ls())

# Import libraries 
library(rattle)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(caret)
library(modelsummary)
library(ranger)
library(Hmisc)
library(knitr)
library(kableExtra)
library(xtable)
library(rpart)
library(mosaic)
library(broom)
library(tidyr)
library(xtable)

# Load data
setwd("/Users/ramzi.chariag/Documents/CEU/PhD/ML Prediction")
listings <- read.csv("./assignment_2/data/listings_sentiment.csv")

```

\textbf{Intro and Context:}
The task is to build a model that predicts the price of small to mid-sized apartments hosting 2 to 6 people. We begin by looking at the variable property type, only to find that the descriptions of the variables do not exactly match what we are looking for. Many of these could be regarded as small to mid-sized apartments that could house 2 to 6 people. Since Property type does not help much, we can look at the number of people that the apartment accommodates, and restrict that to the interval specified, while also picking the property type that sounds like it could include small to mid size houses (granted, more expert knowledge of real estate would be required here).

```{r exploring database}
listings %>% top_n(10)

# distributions of some key variables

group_by(listings, property_type)%>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) 

group_by(listings, accommodates)%>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>% top_n(10)

group_by(listings, neighbourhood_cleansed)%>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>% top_n(10)


```

\textbf{Feature Engineering:}

Next, I use the reviews data to generate a review sentiment score for each listing. The code is in the script 'comment sentiment' which may take some time to run. In fact the sentiment analysis algorithm has a memory limit and cannot take a vector above a certain size, so I had to break the task into chunks and do it in a loop. An important detail here is that the algorithm only works on English language and will give scores really close to zero for other languages. For non-latin alphabets, it gives no value at all, which I imputed with zero. The rationale behind this is that a statement in a different language should be neutral to the reader. In any case, most reviews are in English. Then, I goup reviews by listing id and take an average over the sentiment score, then merge it with listings. Next, we turn to feature engineering.     

```{r restrict data}
# Restrict the dataset to entire units that house between 2 and 6 people
# This is the closest thing to the description required
listings <- listings %>% filter(between(accommodates, 2, 6),
                            property_type %in% c("Entire rental unit", 
                                                  "Entire condo", 
                                                  "Entire townhouse",
                                                  'Entire serviced apartment',
                                                  'Entire guesthouse',
                                                  'Entire guest suite'
                                                      ))
 
```

In the following chunk, I tried to think about all the variables which could be interpreted as a zero in case of no value. I was hesitant about bedrooms, but then I remebered my friends who live there who tell me that Paris is infamous for its small urban apartments. People jusometimes just split their own house to rent a part of it for some extra money. People who opten for this strategy would deliberately not fill information about cncerning "bedroom", so I ended up deciding on zero for it as well. The other ones are more or less obvious. In here, I also delete the variables that I did not end up using later in my analysis.

```{r impute sentiment and generate response speed}
# Impute sentiment score and and reviews per month, 0 in case of NA
# Generate response speed variable, and drop unneeded columns
(listings <- listings %>% mutate (sentiment = coalesce(sentiment, 0),
                      reviews_per_month = coalesce(reviews_per_month, 0),
                      bedrooms = coalesce(bedrooms, 0),
                      review_scores_rating = coalesce(review_scores_rating, 0),
                      review_scores_checkin = coalesce(review_scores_checkin, 0),
                      review_scores_communication = coalesce(review_scores_communication, 0),
                      review_scores_location = coalesce(review_scores_location, 0))%>%
                     
  mutate(quick_response= ifelse(
    host_response_time == 'within an hour'| 
      host_response_time == 'within a few hours', 1, 0))%>%
    dplyr::select(-c(X, host_thumbnail_url,
    host_picture_url,
    listing_url,
    picture_url,
    host_url,
    description,
    neighborhood_overview,
    host_about,
    host_neighbourhood,
    host_response_time,
    host_total_listings_count,
    name,
    host_location,
    host_verifications,
    neighbourhood,
    neighbourhood_group_cleansed,
    bathrooms,
    amenities,
    minimum_nights_avg_ntm,
    maximum_nights_avg_ntm,
    number_of_reviews_ltm,
    scrape_id,
    source,
    host_name,
    calendar_updated,
    number_of_reviews_l30d,
    last_review,
    number_of_reviews_l30d,
    calculated_host_listings_count,
    calculated_host_listings_count_entire_homes,
    calculated_host_listings_count_private_rooms,
    calculated_host_listings_count_shared_rooms
    ))
 )

```

The information contained in baths is an interaction between the number and type of bath. Best to leave it as is, and use it as a factor. If one rents an Airbnb apartment, the number of bathrooms matters only as they are accessible. Coordinates may be used for visualisation, especially maps, so It is always a good idea to keep them. 'f_room_type' is useless because they all have the same category, and 'mobility lease' has very little variance, to be of any use either. In the following chunk, I change categories into factors, and character types into numerics, which also required getting rid of some symbols like the dollar sign and the comma separating digits of large numbers. An interesting variable I generate here as well is host experience, which I will use as a polynomial later on.

```{r feature engineering part 1}
# Rename and factor property types 
listings <- listings %>%
  mutate(
    property_type = ifelse(listings$property_type == 
                             "Entire rental unit", "rental unit",
                           ifelse(listings$property_type == 
                             "Entire condo", "condo", 
                           ifelse(listings$property_type == 
                             "Entire serviced apartment", "serviced apartment", 
                           ifelse(listings$property_type == 
                             "Entire guesthouse", "guesthouse", 
                           ifelse(listings$property_type == 
                             "Entire guest suite", "guest suite", "."))))))%>%
      mutate(
                            f_property_type = factor(property_type))

#Room type as factor
table(listings$room_type)
listings <- listings %>%
  mutate(f_room_type = factor(room_type))

# Rename room type because it is too long
listings$f_room_type <- factor(ifelse(listings$f_room_type== "Entire home/apt", 
                                                              "Entire/Apt",
                        ifelse(listings$f_room_type== "Private room", "Private",
                        ifelse(listings$f_room_type== "Shared room",
                               "Shared", "."))))

# If bathroom is empty, we assume it is 0
listings <- listings %>%
  mutate(
    bathrooms_text =  ifelse(
      (bathrooms_text == ''), 
      '0 baths', bathrooms_text))

# bathroom factor
listings <- listings %>%
  mutate(f_bathroom = factor(bathrooms_text))

# neighbourhood as factor
listings <- listings %>%
  mutate(f_neighbourhood = factor(neighbourhood_cleansed))

# Superhost, profile pic and verified identity dummies
listings <- listings %>%
  mutate(superhost = (host_is_superhost=='t'),
         profile_pic = (host_has_profile_pic=='t'),
         verified_host = (host_identity_verified =='t'),
         instant_bookable = (instant_bookable == 't'),
         has_availability =(has_availability == 't'),
         mobility_lease = (license == 'Available with 
                           a mobility lease only ("bail mobilit√©")')
         )

# Convert numeric variables 
listings <- listings %>%
  mutate(price = as.numeric(gsub('[$,]','',price)),
         minimum_nights = as.numeric(minimum_nights),
         minimum_minimum_nights = as.numeric(minimum_minimum_nights),
         maximum_minimum_nights = as.numeric(maximum_minimum_nights),
         maximum_nights = as.numeric(maximum_nights),
         maximum_maximum_nights = as.numeric(maximum_maximum_nights),
         minimum_maximum_nights = as.numeric(minimum_maximum_nights),
         host_response_rate = gsub('[%]','',host_response_rate),
         host_response_rate = as.numeric(gsub('[N/A]','0',host_response_rate)),
         host_acceptance_rate = gsub('[%]','',host_acceptance_rate),
         host_acceptance_rate = as.numeric(
                              gsub('[N/A]','0',host_acceptance_rate))
         )

# Create host experience
listings <- listings %>%
  mutate(
    host_experience = as.numeric(as.Date(last_scraped,format="%Y-%m-%d") -
                                as.Date(host_since ,format="%Y-%m-%d"))/365)

# Create days since first review
listings <- listings %>%
  mutate(
    n_days_since = as.numeric(as.Date(last_scraped,format="%Y-%m-%d") -
                                as.Date(first_review ,format="%Y-%m-%d")))

# Drop already used vars
listings <- listings %>%
    dplyr::select(-c(host_since, first_review,
                     bathrooms_text,
                     neighbourhood_cleansed,
                     host_id,
                     host_is_superhost,
                     host_has_profile_pic,
                     host_identity_verified,
                     instant_bookable,
                     has_availability,
                     calendar_last_scraped,
                     last_scraped,
                     license,
                     property_type,
                     room_type,
                     f_room_type,
                     mobility_lease
    ))

# Rename sentiment
listings <- listings %>% 
  rename(review_sentiment = sentiment)

```
Now, it is time to look at the variable of interest, which is the price. As usual, the distribution has a fat tail to the right, so I take a log. This can be useful for interpretation purposes, because the log allows us to interpret the models in relative terms.

```{r feature engineering part 2}

# Squares and further values to create
listings <- listings %>%
  mutate(accommodates2 = accommodates^2, 
         host_experience2 = host_experience^2, 
         bedrooms2 = bedrooms^2,
         beds2 = beds^2,
         minimum_nights2 = minimum_nights^2 
        )

#####################
### look at price ###
#####################
summary(listings$price)

listings <- listings %>%
  mutate(lprice = log(price))

listings <- listings %>%
  filter(price <1000)

plot(density(listings$price, kernel = "epanechnikov"),
     lwd = 2, main = "Price Density")

plot(density(listings$lprice, kernel = "epanechnikov"), 
     lwd = 2, main = "Ln(price) Density")

# Change Infinite values with NaNs
for (j in 1:ncol(listings) ) data.table::set(listings,
                                             which(is.infinite(listings[[j]])), j, NA)


```
In the following chunk, I do the final preanalysis cleaning, and make sure that there are no missings in the final workbook. The rule I follow is quite straight forward: drop if no target, impute when few, not that important, and Replace missing variables re reviews with zero, when no review and add flags. I also had to make some assumptions about whether the absence of a variable means a zero or a one like earlier. Host acceptance rate is a zero, and host listings count is a one (it cannot be less, mechanically, because we already know one observation). 
```{r pre-analysis cleaning}

# where do we have missing variables now?
to_filter <- sapply(listings, function(x) sum(is.na(x)))
to_filter[to_filter > 0]

# what to do with missing values? 
# 1. drop if no target
listings <- listings %>%
  drop_na(lprice)

# 2. impute when few, not that important
listings <- listings %>%
  mutate(
    maximum_maximum_nights =  ifelse(
      is.na(maximum_maximum_nights), 
      median(maximum_maximum_nights, na.rm = T), maximum_maximum_nights), 
    
        minimum_maximum_nights =  ifelse(
      is.na(minimum_maximum_nights), 
      median(minimum_maximum_nights, na.rm = T), minimum_maximum_nights), 
    
        minimum_minimum_nights =  ifelse(
      is.na(minimum_minimum_nights), 
      median(minimum_minimum_nights, na.rm = T), minimum_minimum_nights), 
    
        maximum_minimum_nights =  ifelse(
      is.na(maximum_minimum_nights), 
      median(maximum_minimum_nights, na.rm = T), maximum_minimum_nights), 
    
    host_acceptance_rate = ifelse(
      is.na(host_acceptance_rate),
      0, host_acceptance_rate), # assume 0 in the absence of response rate
    
    host_response_rate=ifelse(is.na(host_response_rate),0, host_response_rate),
    
    host_experience=ifelse(is.na(host_experience),0, host_experience),
    
    host_experience2=ifelse(is.na(host_experience2),0, host_experience2),
    
    host_listings_count=ifelse(
      is.na(host_listings_count),1, host_response_rate), # assume 1 
    
    beds=ifelse(is.na(beds),accommodates, beds), # assume 1 bed per person
    beds2=ifelse(is.na(beds2),accommodates2, beds2)
  ) 

# 3. Replace missing variables re reviews with zero, when no review + add flags
listings <- listings %>%
  mutate(
    flag_days_since=ifelse(is.na(n_days_since),1, 0),
    n_days_since =  ifelse(
      is.na(n_days_since), median(n_days_since, na.rm = T), n_days_since),
    
        flag_review_scores_accuracy=ifelse(is.na(review_scores_accuracy),1, 0),
    review_scores_accuracy =  ifelse(
      is.na(review_scores_accuracy), 
      median(review_scores_accuracy, na.rm = T), review_scores_accuracy),
    
            flag_review_scores_cleanliness=ifelse(is.na(review_scores_cleanliness),1, 0),
    review_scores_cleanliness =  ifelse(
      is.na(review_scores_cleanliness), 
      median(review_scores_cleanliness, na.rm = T), review_scores_cleanliness),
    
                flag_review_scores_value=ifelse(is.na(review_scores_value),1, 0),
    review_scores_value =  ifelse(
      is.na(review_scores_value), 
      median(review_scores_value, na.rm = T), review_scores_value),
    
    )

# N=42729

# Save version with coordinates before dropping them
listings_coordinates <- listings 

listings <- listings %>% dplyr::select(-c(latitude,longitude, id, price))

# save workbook
setwd("/Users/ramzi.chariag/Documents/CEU/PhD/ML Prediction")
write_csv(listings,"./assignment_2/data/airbnb_paris_workfile_adj_book.csv")

```
I then just do one last check to make sure everything is the way it should be.

```{r check for missings again}
to_filter <- sapply(listings, function(x) sum(is.na(x)))
to_filter[to_filter > 0]

skimr::skim(listings)
```

I will use the same variables for all models, which is all of the ones in the dataframe by now. The variables are quite unbalanced, so I avoided interactions, because that can cause issues with cross-validation. We are very likely to end up with samples that have variables with zero variance. This can break some of the models.


```{r sample split}

# create train and holdout samples -------------------------------------------
# train is where we do it all, incl CV

set.seed(42)

# First pick a smaller than usual training set so that models run faster and check if works
# If works, start anew without these two lines
# try <- createDataPartition(listings$lprice, p = 0.2, list = FALSE)
# listings <- listings[try, ]


train_indices <- as.integer(createDataPartition(listings$lprice, p = 0.7, list = FALSE))
data_train <- listings[train_indices, ]
data_holdout <- listings[-train_indices, ]

dim(data_train)
dim(data_holdout)

vars <- names(listings)

```

Since I opted for not including interaction terms, I might as well just go for 10 fold cross validation instead of 5. I run the following models respectively: cross_validated OLS, LASSO, CART and random forest. Then I check their respective results, and try to present the most useful graph for each given model. Then I check, their RMSE in the holdout set and report that next to their respective RMSE from the test set. The results are quite similar, which is a good sign. Overfitting is not really a threat in this situation because the size of the dataset is really large compared to the number of variables and how deep the trees run. If anything, we are more likely to be underfitting. 

```{r Cross-validated OLS}
# do 10-fold CV
train_control <- trainControl(method = "cv",
                              number = 10,
                              verboseIter = FALSE)

# x vector for OLS 
predictors_ols<- c(names(dplyr::select(data_train,
                                 -c(lprice,f_bathroom))))

set.seed(42)
system.time({
ols_model <- train(
  formula(paste0("lprice ~", paste0(predictors_ols, collapse = " + "))),
  data = data_train,
  method = "lm",
  trControl = train_control
)
})

ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))
```

```{r models LASSO}

predictors_lasso<- c(names(dplyr::select(data_train,
                                 -c(lprice, f_bathroom))))

# Lasso

set.seed(42)
system.time({
lasso_model <- train(formula(paste0("lprice ~ ", paste0(predictors_lasso, collapse = " + "))),
  data = data_train,
  method = "glmnet",
  preProcess = c("center", "scale"),
  tuneGrid =  expand.grid("alpha" = 0.1, "lambda" = seq(0.000001, 0.0045, by = 0.00003)),
  trControl = train_control
)
})

lasso_coeffs <- coef(
    lasso_model$finalModel,
    lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  rename(lasso_coefficient = 's1')  

# collect coeffs in the same dataframe
lasso_coeffs_non_null <- lasso_coeffs[!lasso_coeffs$lasso_coefficient == 0,]

regression_coeffs <- merge(ols_model_coeffs_df, lasso_coeffs_non_null,
                           by = "variable", all=TRUE)

(lasso_plot <- plot(lasso_model, main='Lasso Hyperparameter'))
regression_coeffs

```
I keep the regression coefficients just in case.

```{r save LASSO plot}
setwd("/Users/ramzi.chariag/Documents/CEU/PhD/ML Prediction")
png("./assignment_2/output/lasso_plot.png")
plot(lasso_model, main='Lasso Hyperparameter')
dev.off()

```

```{r CART}
# predictors for CART

predictors_CART <- names(dplyr::select(data_train,
                                 -c(lprice, f_bathroom)))
# CART
set.seed(42)
system.time({
cart_model <- train(
  formula(paste0("lprice ~", paste0(predictors_CART, collapse = " + "))),
  data = data_train,
  method = "rpart",
  tuneLength = 15,
  trControl = train_control
)
})

```
```{r plot CART}

setwd("/Users/ramzi.chariag/Documents/CEU/PhD/ML Prediction")
png("./assignment_2/output/CART_plot.png")
fancyRpartPlot(cart_model$finalModel, sub = "")
dev.off()

fancyRpartPlot(cart_model$finalModel, sub = "")

```
The number of observations in each final node is reasonably high. We can also infer the important variables from the tree which are for the most part bedrooms, how many people the apartment can accommodate, and availability.

For random forest, I fix the stopping rule at 10 observations per final node, and go over a wide array of tree numbers. The reason behind this is that it makes more sense to optimize over that since changing minimum node size kep giving me a monotone change in RMSE (I tied numbers that range from 5 to 100), and ended up settling on 10, because it gave seemingly reasonable results. 

```{r RF}

# set tuning
tune_grid <- expand.grid(
  .mtry = c( 2, 4, 6, 10, 14, 18, 22, 24),
  .splitrule = "variance",
  .min.node.size = 10
)

predictors_RF <- predictors_CART

# RF model model with automatic tuning
set.seed(42)
system.time({
rf_model_1 <- train(
  formula(paste0("lprice ~", paste0(predictors_RF, collapse = " + "))),
  data = data_train,
  method = "ranger",
  trControl = train_control,
  tuneGrid = tune_grid,
  importance = "impurity"
)
})
rf_model_1

```

```{r RF Model results}

rf_tuning <- rf_model_1$results %>%
  dplyr::select(mtry, min.node.size, RMSE) %>%
  dplyr::rename(nodes = min.node.size) %>%
  spread(key = mtry, value = RMSE) %>%
  select(-nodes) %>%
  t() %>% data.frame()

names(rf_tuning) <-  'RMSE'
```

To get the area under the ROC curve for each predictor, the filterVarImp function can be used. The area under the ROC curve is computed for each class.ROC IMP shows the area under the ROC curve.

```{r RF variable importance}

rf_Imp <- varImp(rf_model_1, scale = TRUE)


roc_imp <- filterVarImp(x = data_train[, -ncol(data_train)], y = data_train$lprice)


setwd("/Users/ramzi.chariag/Documents/CEU/PhD/ML Prediction")
png("./assignment_2/output/rf_var_imp.png")
plot(rf_Imp, top = 20, main='RF variable importance ranking')
dev.off()

plot(rf_Imp, top = 20, main='RF variable importance ranking')

rf_Imp

```
The random forest givest out a similar ranking of the most important variables. These variables make economically, because people who rent Airbnb are usually staying for a short period of time. They tend to have savings in preparation for their trip, and they also tend to be quite inelastic about whether there is a spot for them to sleep or not. As for availability, I think that there is probably a reverse causality story that might be going on in there. Hosts with more expensive houses, usually offer a better service which earns them more on the margin, hence they are more available. 


```{r Results summary}

results_summary <- data.frame(
   Model = c("OLS","LASSO","CART","RF"),
   RMSE = c(ols_model$results$RMSE,min(lasso_model$results$RMSE),
            min(cart_model$results$RMSE),min(rf_model_1$results$RMSE)))

round_df <- function(df, digits) {
  nums <- vapply(df, is.numeric, FUN.VALUE = logical(1))

  df[,nums] <- round(df[,nums], digits = digits)

  (df)
}

# Holdout set RMSE
RMSE_ols_holdout <- sqrt(mean((predict(ols_model,dplyr::select(data_holdout,
                                    predictors_ols))-data_holdout$lprice)^2))


RMSE_lasso_holdout <- sqrt(mean((predict(lasso_model,dplyr::select(data_holdout,
                                    predictors_lasso))-data_holdout$lprice)^2))


RMSE_cart_holdout <- sqrt(mean((predict(cart_model,dplyr::select(data_holdout,
                                    predictors_CART))-data_holdout$lprice)^2))

RMSE_rf_holdout <- sqrt(mean((predict(rf_model_1,dplyr::select(data_holdout,
                                    predictors_RF))-data_holdout$lprice)^2))


results_summary <- results_summary %>% mutate(RMSE_holdout = c(RMSE_ols_holdout,
                                              RMSE_lasso_holdout,
                                              RMSE_cart_holdout,
                                              RMSE_rf_holdout)) 

round_df(results_summary, digits=3)
mean(data_train$lprice)

```
Running the models on the holdout set gives very similar RMSE scores, which is good news. This provides another layer of affirmation that our models are well specified. The ranking of the models is to be expected. LASSO does not really bring much to the table over OLS, due to the fact that dimensionality reduction is not the issue in this situation. CART performs horribly. That is in part, due to the model being not so capable, and in another part due to me specifying a strict stopping rule. As for the random forest, it provides the best results, and it captures the main drivers of the price change in a way that makes sense. 


Link to repo: https://github.com/RamziChariag/Prediction-ML

